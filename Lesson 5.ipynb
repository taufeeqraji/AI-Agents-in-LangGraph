{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c2a9c12",
   "metadata": {},
   "source": [
    "# Lesson 5: Human in the Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fca089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f857d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f42bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "\"\"\"\n",
    "In previous examples we've annotated the `messages` state key\n",
    "with the default `operator.add` or `+` reducer, which always\n",
    "appends new messages to the end of the existing messages array.\n",
    "\n",
    "Now, to support replacing existing messages, we annotate the\n",
    "`messages` key with a customer reducer function, which replaces\n",
    "messages with the same `id`, and appends them otherwise.\n",
    "\"\"\"\n",
    "def reduce_messages(left: list[AnyMessage], right: list[AnyMessage]) -> list[AnyMessage]:\n",
    "    # assign ids to messages that don't have them\n",
    "    for message in right:\n",
    "        if not message.id:\n",
    "            message.id = str(uuid4())\n",
    "    # merge the new messages with the existing messages\n",
    "    merged = left.copy()\n",
    "    for message in right:\n",
    "        for i, existing in enumerate(merged):\n",
    "            # replace any existing messages with the same id\n",
    "            if existing.id == message.id:\n",
    "                merged[i] = message\n",
    "                break\n",
    "        else:\n",
    "            # append any new messages to the end\n",
    "            merged.append(message)\n",
    "    return merged\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], reduce_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b29c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1514bb30",
   "metadata": {},
   "source": [
    "## Manual human approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, system=\"\", checkpointer=None):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(\n",
    "            checkpointer=checkpointer,\n",
    "            interrupt_before=[\"action\"]\n",
    "        )\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        print(state)\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d78fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Whats the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d841dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d802b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread).next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a809bba",
   "metadata": {},
   "source": [
    "### continue after interrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ddd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27480cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19adbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de6df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(\"Whats the weather in LA?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)\n",
    "while abot.graph.get_state(thread).next:\n",
    "    print(\"\\n\", abot.graph.get_state(thread),\"\\n\")\n",
    "    _input = input(\"proceed?\")\n",
    "    if _input != \"y\":\n",
    "        print(\"aborting\")\n",
    "        break\n",
    "    for event in abot.graph.stream(None, thread):\n",
    "        for v in event.values():\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e088b5cf",
   "metadata": {},
   "source": [
    "## Modify State\n",
    "Run until the interrupt and then modify the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afc2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(\"Whats the weather in LA?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d6989",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_values = abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_values.values['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_values.values['messages'][-1].tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23147c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = current_values.values['messages'][-1].tool_calls[0]['id']\n",
    "current_values.values['messages'][-1].tool_calls = [\n",
    "    {'name': 'tavily_search_results_json',\n",
    "  'args': {'query': 'current weather in Louisiana'},\n",
    "  'id': _id}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.update_state(thread, current_values.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64203514",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc624003",
   "metadata": {},
   "source": [
    "## Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd3cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "for state in abot.graph.get_state_history(thread):\n",
    "    print(state)\n",
    "    print('--')\n",
    "    states.append(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay = states[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b764343",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18c7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, to_replay.config):\n",
    "    for k, v in event.items():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dfe43d",
   "metadata": {},
   "source": [
    "## Go back in time and edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaceec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae3d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = to_replay.values['messages'][-1].tool_calls[0]['id']\n",
    "to_replay.values['messages'][-1].tool_calls = [{'name': 'tavily_search_results_json',\n",
    "  'args': {'query': 'current weather in LA, accuweather'},\n",
    "  'id': _id}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e1995",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_state = abot.graph.update_state(to_replay.config, to_replay.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e0def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, branch_state):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb381885",
   "metadata": {},
   "source": [
    "## Add message to a state at a given time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03744ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49641063",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = to_replay.values['messages'][-1].tool_calls[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43887780",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_update = {\"messages\": [ToolMessage(\n",
    "    tool_call_id=_id,\n",
    "    name=\"tavily_search_results_json\",\n",
    "    content=\"54 degree celcius\",\n",
    ")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8758fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_and_add = abot.graph.update_state(\n",
    "    to_replay.config, \n",
    "    state_update, \n",
    "    as_node=\"action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6030645",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, branch_and_add):\n",
    "    for k, v in event.items():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50956a71",
   "metadata": {},
   "source": [
    "# Extra Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b185222",
   "metadata": {},
   "source": [
    "## Build a small graph\n",
    "This is a small simple graph you can tinker with if you want more insight into controlling state memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5105f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa075023",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    lnode: str\n",
    "    scratch: str\n",
    "    count: Annotated[int, operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74852db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node1(state: AgentState):\n",
    "    print(f\"node1, count:{state['count']}\")\n",
    "    return {\"lnode\": \"node_1\",\n",
    "            \"count\": 1,\n",
    "           }\n",
    "def node2(state: AgentState):\n",
    "    print(f\"node2, count:{state['count']}\")\n",
    "    return {\"lnode\": \"node_2\",\n",
    "            \"count\": 1,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ae8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    return state[\"count\"] < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"Node1\", node1)\n",
    "builder.add_node(\"Node2\", node2)\n",
    "\n",
    "builder.add_edge(\"Node1\", \"Node2\")\n",
    "builder.add_conditional_edges(\"Node2\", \n",
    "                              should_continue, \n",
    "                              {True: \"Node1\", False: END})\n",
    "builder.set_entry_point(\"Node1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a0b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beb6d58",
   "metadata": {},
   "source": [
    "### Run it!\n",
    "Now, set the thread and run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": str(1)}}\n",
    "graph.invoke({\"count\":0, \"scratch\":\"hi\"},thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7337e982",
   "metadata": {},
   "source": [
    "### Look at current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce35fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the current state. Note the `values` which are the AgentState. Note the `config` and the `thread_ts`. You will be using those to refer to snapshots below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a305cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4f9aa8",
   "metadata": {},
   "source": [
    "### Look at state history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4782a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in graph.get_state_history(thread):\n",
    "    print(state, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08566700",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "for state in graph.get_state_history(thread):\n",
    "    states.append(state.config)\n",
    "    print(state.config, state.values['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04cd26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "states[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(states[-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f27dc4a",
   "metadata": {},
   "source": [
    "### Go Back in Time\n",
    "Use that state in `invoke` to go back in time. Notice it uses states[-3] as *current_state* and continues to node2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b539e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke(None, states[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347e8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": str(1)}}\n",
    "for state in graph.get_state_history(thread):\n",
    "    print(state.config, state.values['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343f2fc",
   "metadata": {},
   "source": [
    "You can see the details below. Lots of text, but try to find the node that start the new branch. Notice the parent *config* is not the previous entry in the stack, but is the entry from state[-3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3368e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": str(1)}}\n",
    "for state in graph.get_state_history(thread):\n",
    "    print(state,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72cf635",
   "metadata": {},
   "source": [
    "### Modify State\n",
    "Let's start by starting a fresh thread and running to clean out history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbdf60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread2 = {\"configurable\": {\"thread_id\": str(2)}}\n",
    "graph.invoke({\"count\":0, \"scratch\":\"hi\"},thread2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e504b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "states2 = []\n",
    "for state in graph.get_state_history(thread2):\n",
    "    states2.append(state.config)\n",
    "    print(state.config, state.values['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0db4be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_state = graph.get_state(states2[-3])\n",
    "save_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf1e1c",
   "metadata": {},
   "source": [
    "Now modify the values. One subtle item to note: Recall when agent state was defined, `count` used `operator.add` to indicate that values are *added* to the current value. Here, `-3` will be added to the current count value rather than replace it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_state.values[\"count\"] = -3\n",
    "save_state.values[\"scratch\"] = \"hello\"\n",
    "save_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7306a28d",
   "metadata": {},
   "source": [
    "Now update the state. This creates a new entry at the *top*, or *latest* entry in memory. This will become the current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0c518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state(thread2,save_state.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8b552",
   "metadata": {},
   "source": [
    "Current state is at the top. You can match the `thread_ts`.\n",
    "Notice the `parent_config`, `thread_ts` of the new node - it is the previous node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, state in enumerate(graph.get_state_history(thread2)):\n",
    "    if i >= 3:  #print latest 3\n",
    "        break\n",
    "    print(state, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a269e5d4",
   "metadata": {},
   "source": [
    "### Try again with `as_node`\n",
    "When writing using `update_state()`, you want to define to the graph logic which node should be assumed as the writer. What this does is allow th graph logic to find the node on the graph. After writing the values, the `next()` value is computed by travesing the graph using the new state. In this case, the state we have was written by `Node1`. The graph can then compute the next state as being `Node2`. Note that in some graphs, this may involve going through conditional edges!  Let's try this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da187508",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state(thread2,save_state.values, as_node=\"Node1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7be4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, state in enumerate(graph.get_state_history(thread2)):\n",
    "    if i >= 3:  #print latest 3\n",
    "        break\n",
    "    print(state, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d4610",
   "metadata": {},
   "source": [
    "`invoke` will run from the current state if not given a particular `thread_ts`. This is now the entry that was just added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0235b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke(None,thread2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab78a2ce",
   "metadata": {},
   "source": [
    "Print out the state history, notice the `scratch` value change on the latest entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1897efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in graph.get_state_history(thread2):\n",
    "    print(state,\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
