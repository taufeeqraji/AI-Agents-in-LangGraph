{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375fb05f",
   "metadata": {},
   "source": [
    "# Lesson 3: Agentic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# load environment variables from .env file\n",
    "_ = load_dotenv()\n",
    "\n",
    "# connect\n",
    "client = TavilyClient(api_key=os.environ.get(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeeaa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run search\n",
    "result = client.search(\"What is in Nvidia's new Blackwell GPU?\",\n",
    "                       include_answer=True)\n",
    "\n",
    "# print the answer\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a22ec8",
   "metadata": {},
   "source": [
    "## Regular search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373002c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose location (try to change to your own city!)\n",
    "\n",
    "city = \"San Francisco\"\n",
    "\n",
    "query = f\"\"\"\n",
    "    what is the current weather in {city}?\n",
    "    Should I travel there today?\n",
    "    \"weather.com\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "import re\n",
    "\n",
    "ddg = DDGS()\n",
    "\n",
    "def search(query, max_results=6):\n",
    "    try:\n",
    "        results = ddg.text(query, max_results=max_results)\n",
    "        return [i[\"href\"] for i in results]\n",
    "    except Exception as e:\n",
    "        print(f\"returning previous results due to exception reaching ddg.\")\n",
    "        results = [ # cover case where DDG rate limits due to high deeplearning.ai volume\n",
    "            \"https://weather.com/weather/today/l/USCA0987:1:US\",\n",
    "            \"https://weather.com/weather/hourbyhour/l/54f9d8baac32496f6b5497b4bf7a277c3e2e6cc5625de69680e6169e7e38e9a8\",\n",
    "        ]\n",
    "        return results  \n",
    "\n",
    "\n",
    "for i in search(query):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4734e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_weather_info(url):\n",
    "    \"\"\"Scrape content from the given URL\"\"\"\n",
    "    if not url:\n",
    "        return \"Weather information could not be found.\"\n",
    "    \n",
    "    # fetch data\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        return \"Failed to retrieve the webpage.\"\n",
    "\n",
    "    # parse result\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a95aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use DuckDuckGo to find websites and take the first result\n",
    "url = search(query)[0]\n",
    "\n",
    "# scrape first wesbsite\n",
    "soup = scrape_weather_info(url)\n",
    "\n",
    "print(f\"Website: {url}\\n\\n\")\n",
    "print(str(soup.body)[:50000]) # limit long outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract text\n",
    "weather_data = []\n",
    "for tag in soup.find_all(['h1', 'h2', 'h3', 'p']):\n",
    "    text = tag.get_text(\" \", strip=True)\n",
    "    weather_data.append(text)\n",
    "\n",
    "# combine all elements into a single string\n",
    "weather_data = \"\\n\".join(weather_data)\n",
    "\n",
    "# remove all spaces from the combined text\n",
    "weather_data = re.sub(r'\\s+', ' ', weather_data)\n",
    "    \n",
    "print(f\"Website: {url}\\n\\n\")\n",
    "print(weather_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b346731",
   "metadata": {},
   "source": [
    "## Agentic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run search\n",
    "result = client.search(query, max_results=1)\n",
    "\n",
    "# print first result\n",
    "data = result[\"results\"][0][\"content\"]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e27160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pygments import highlight, lexers, formatters\n",
    "\n",
    "# parse JSON\n",
    "parsed_json = json.loads(data.replace(\"'\", '\"'))\n",
    "\n",
    "# pretty print JSON with syntax highlighting\n",
    "formatted_json = json.dumps(parsed_json, indent=4)\n",
    "colorful_json = highlight(formatted_json,\n",
    "                          lexers.JsonLexer(),\n",
    "                          formatters.TerminalFormatter())\n",
    "\n",
    "print(colorful_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
